#!/usr/bin/env python3
"""
read_performance_csv.py - Read and plot performance test CSV data

Reads CSV files generated by performance tests (SWCLOCK_PERF_CSV=1)
and creates time series plots for visualization.

Supports caching for faster repeated analysis.
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import glob
import sys
import os

# Import cache utilities
sys.path.insert(0, str(Path(__file__).parent))
from cache_utils import AnalysisCache, load_csv_with_cache


def find_performance_csvs(logs_dir: str = "logs") -> Dict[str, List[str]]:
    """
    Find all performance test CSV files grouped by test name.
    
    Args:
        logs_dir: Directory containing CSV files
        
    Returns:
        Dictionary mapping test names to list of CSV file paths
    """
    logs_path = Path(logs_dir)
    csv_files = sorted(logs_path.glob("*-Perf_*.csv"))
    
    tests = {}
    for csv_file in csv_files:
        # Extract test name from filename: YYYYMMDD-HHMMSS-Perf_TestName.csv
        parts = csv_file.stem.split('-', 2)
        if len(parts) >= 3:
            test_name = parts[2]  # e.g., "Perf_DisciplineTEStats_MTIE_TDEV"
            if test_name not in tests:
                tests[test_name] = []
            tests[test_name].append(str(csv_file))
    
    return tests


def read_te_csv(csv_file: str) -> pd.DataFrame:
    """
    Read a performance test CSV file containing TE measurements.
    
    Args:
        csv_file: Path to CSV file
        
    Returns:
        DataFrame with columns: timestamp_ns, te_ns, timestamp_s, te_us
    """
    df = pd.read_csv(csv_file, comment='#')
    
    # Convert to more readable units
    df['timestamp_s'] = df['timestamp_ns'] / 1e9
    df['te_us'] = df['te_ns'] / 1e3
    
    return df


def plot_te_timeseries(df: pd.DataFrame, test_name: str, output_file: str):
    """
    Plot time error time series.
    
    Args:
        df: DataFrame with TE data
        test_name: Name of the test
        output_file: Output plot filename
    """
    fig, ax = plt.subplots(figsize=(12, 6))
    
    ax.plot(df['timestamp_s'], df['te_us'], 'b-', linewidth=0.5, alpha=0.7)
    ax.axhline(y=0, color='k', linestyle='--', linewidth=0.5, alpha=0.5)
    
    ax.set_xlabel('Time (s)', fontsize=12)
    ax.set_ylabel('Time Error (µs)', fontsize=12)
    ax.set_title(f'{test_name}\nTime Error vs Time', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    
    # Add statistics annotation
    stats_text = f'Mean: {df["te_us"].mean():.2f} µs\n'
    stats_text += f'Std: {df["te_us"].std():.2f} µs\n'
    stats_text += f'Max: {df["te_us"].max():.2f} µs\n'
    stats_text += f'Min: {df["te_us"].min():.2f} µs'
    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,
            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),
            fontsize=9, family='monospace')
    
    plt.tight_layout()
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"  Generated: {output_file}")


def plot_te_histogram(df: pd.DataFrame, test_name: str, output_file: str):
    """
    Plot time error histogram.
    
    Args:
        df: DataFrame with TE data
        test_name: Name of the test
        output_file: Output plot filename
    """
    fig, ax = plt.subplots(figsize=(10, 6))
    
    n, bins, patches = ax.hist(df['te_us'], bins=50, edgecolor='black', alpha=0.7)
    
    # Add vertical line at mean
    mean_te = df['te_us'].mean()
    ax.axvline(mean_te, color='r', linestyle='--', linewidth=2, label=f'Mean: {mean_te:.2f} µs')
    
    ax.set_xlabel('Time Error (µs)', fontsize=12)
    ax.set_ylabel('Frequency', fontsize=12)
    ax.set_title(f'{test_name}\nTime Error Distribution', fontsize=14, fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"  Generated: {output_file}")


def generate_plots_for_test(csv_file: str, output_dir: str, cache: Optional[AnalysisCache] = None):
    """
    Generate all plots for a single test CSV file.
    
    Args:
        csv_file: Path to CSV file
        output_dir: Directory for output plots
        cache: Optional cache manager for faster repeated runs
    """
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    csv_path = Path(csv_file)
    
    # Extract test name from filename
    filename = csv_path.stem
    parts = filename.split('-', 2)
    test_name = parts[2] if len(parts) >= 3 else filename
    
    # Check if plots already exist and are fresh
    base_name = f"{filename}"
    timeseries_plot = output_path / f"{base_name}_timeseries.png"
    histogram_plot = output_path / f"{base_name}_histogram.png"
    
    # Skip if both plots exist and are newer than CSV
    if (timeseries_plot.exists() and histogram_plot.exists() and 
        os.path.getmtime(timeseries_plot) >= os.path.getmtime(csv_path) and
        os.path.getmtime(histogram_plot) >= os.path.getmtime(csv_path)):
        print(f"\n{test_name}: Plots are fresh, skipping regeneration")
        return, 
                      use_cache: bool = True):
    """
    Find all performance CSV files and generate plots for each.
    
    Args:
        logs_dir: Directory containing CSV files
        output_dir: Directory for output plots
        use_cache: Whether to use caching (default: True)
    """
    tests = find_performance_csvs(logs_dir)
    
    if not tests:
        print(f"No performance CSV files found in {logs_dir}")
        return
    
    print(f"Found {len(tests)} test types with CSV data:")
    for test_name, csv_files in tests.items():
        print(f"  {test_name}: {len(csv_files)} file(s)")
    
    # Initialize cache if enabled
    cache = None
    if use_cache:
        cache_dir = Path(output_dir).parent / '.cache'
        cache = AnalysisCache(cache_dir, enabled=True)
        print(f"\nCache: {cache.get_stats()}")
    
    # Process most recent CSV for each test
    for test_name, csv_files in tests.items():
        # Use most recent file (files are sorted)
        latest_csv = csv_files[-1]
        generate_plots_for_test(latest_csv, output_dir, cache)
    
    if cache:
        stats = cache.get_stats()
        print(f"\nCache stats: {stats['total_files']} files, {stats['total_size_mb']:.2f} MB"
    Args:
        logs_dir: Directory containing CSV files
        output_dir: Directory for output plots
    """
    tests = find_performance_csvs(logs_dir)
    
    if not tests:
        print(f"No performance CSV files found in {logs_dir}")
        return
    
    print(f"Found {len(tests)} test types with CSV data:")
    for test_name, csv_files in tests.items():
        print(f"  {test_name}: {len(csv_files)} file(s)")
    
    # Process most recent CSV for each test
    for test_name, csv_files in tests.items():
        # Use most recent file (files are sorted)
        latest_csv = csv_files[-1]
        generate_plots_for_test(latest_csv, output_dir)
    
    print(f"\n✓ All plots generated in: {output_dir}")


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Generate plots from performance test CSV data'
    )
    parser.add_argument(
        '--logs-dir',
        default='logs',
        help='Directory containing CSV files (default: logs)'
    )
    parser.add_argument(
        '--output-dir',
        default='plots/csv_analysis',
        help='Output directory for plots (default: plots/csv_analysis)'
    )
    parser.add_argument(
        '--csv-file',
        help='Process a specific CSV file instead of searching logs directory'
    )
    parser.add_argument(
        '--no-cache',
        action='store_true',
        help='Disable caching (default: caching enabled)'
    )
    
    args = parser.parse_args()
    
    use_cache = not args.no_cache
    
    # Initialize cache if needed
    cache = None
    if use_cache and args.csv_file:
        cache_dir = Path(args.output_dir).parent / '.cache'
        cache = AnalysisCache(cache_dir, enabled=True)
    
    if args.csv_file:
        generate_plots_for_test(args.csv_file, args.output_dir, cache)
    else:
        generate_all_plots(args.logs_dir, args.output_dir, use_cache)
